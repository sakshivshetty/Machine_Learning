{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy = approx 99%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import pandas\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single forward slash for the directory's name because I do not use windows.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url='https://karki23.github.io/Weather-Data/assignment.html'\n",
    "a=requests.get(url)\n",
    "r=BeautifulSoup(a.content, \"lxml\")\n",
    "cities=r.find_all('a')\n",
    "import csv\n",
    "file_name=\"dataset/\"+\"All_Cities.\"+\"csv\"\n",
    "f=open(file_name, \"a\", newline=\"\")\n",
    "writer=csv.writer(f)\n",
    "writer.writerow(['Date','Location','MinTemp','MaxTemp','Rainfall','Evaporation','Sunshine','WindGustDir','WindGustSpeed','WindDir9am','WindDir3pm','WindSpeed9am','WindSpeed3pm','Humidity9am','Humidity3pm','Pressure9am','Pressure3pm','Cloud9am\t','Cloud3pm','Temp9am','Temp3pm','RainToday','RISK_MM','RainTomorrow'])\n",
    "for x in range(len(cities)):\n",
    "    s=cities[x].get('href')[0:len(cities[x])-5:]    \n",
    "    new_url='https://karki23.github.io/Weather-Data/'+cities[x].get('href')\n",
    "    new_a=requests.get(new_url)\n",
    "    new_r=BeautifulSoup(new_a.content, \"lxml\")\n",
    "    row=new_r.find_all('tr')\n",
    "    row.pop(0) \n",
    "    writer=csv.writer(f)\n",
    "    for i in row:    \n",
    "        column=i.find_all('td')\n",
    "        new_column=[j.text for j in column]\n",
    "        writer.writerow(new_column)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sakshishetty/Desktop/Python\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sakshishetty/Desktop/Python/dataset\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/Users/sakshishetty/Desktop/Python/dataset\")  #CHANGE ACCORDING TO YOUR SYSTEM\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pandas.read_csv('All_Cities.csv')      #File consisting of data of all 49 cities\n",
    "dataset = dataset.drop(columns =['Date','Location'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(read the comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "dataset['RainToday']=encoder.fit_transform(dataset['RainToday'])\n",
    "I initially tried using this method for all the string data, but I got an error I wasn't able to fix, \n",
    "so I opted for the method below.\n",
    "'''\n",
    "\n",
    "dataset['WindGustDir'] = pandas.Categorical(dataset['WindGustDir'])\n",
    "dataset['WindGustDir'] = dataset.WindGustDir.cat.codes\n",
    "dataset['WindDir9am'] = pandas.Categorical(dataset['WindDir9am'])\n",
    "dataset['WindDir9am'] = dataset.WindDir9am.cat.codes\n",
    "dataset['WindDir3pm'] = pandas.Categorical(dataset['WindDir3pm'])\n",
    "dataset['WindDir3pm'] = dataset.WindDir3pm.cat.codes\n",
    "dataset['RainTomorrow'] = pandas.Categorical(dataset['RainTomorrow'])\n",
    "dataset['RainTomorrow'] = dataset.RainTomorrow.cat.codes\n",
    "dataset['RainToday'] = pandas.Categorical(dataset['RainToday'])\n",
    "dataset['RainToday'] = dataset.RainToday.cat.codes\n",
    "\n",
    "dataset[['WindGustDir','WindDir9am','WindDir3pm']] = dataset[['WindGustDir','WindDir9am','WindDir3pm']].astype(float)\n",
    "\n",
    "#to get rid of negative values\n",
    "import numpy as np\n",
    "dataset[['WindDir9am']] = np.where(dataset[['WindDir9am']]<0, 0, dataset[['WindDir9am']])\n",
    "dataset[['WindGustDir']] = np.where(dataset[['WindGustDir']]<0, 0, dataset[['WindGustDir']])\n",
    "dataset[['WindDir3pm']] = np.where(dataset[['WindDir3pm']]<0, 0, dataset[['WindDir3pm']])\n",
    "dataset[['RainToday']] = np.where(dataset[['RainToday']]<0, 0, dataset[['RainToday']])\n",
    "\n",
    "#filling the missing values with mean\n",
    "dataset.fillna(dataset.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = dataset.drop(columns=['RainTomorrow'])\n",
    "ytrain = dataset['RainTomorrow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0723 23:08:55.587437 4622742976 deprecation_wrapper.py:119] From /Users/sakshishetty/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0723 23:08:55.628325 4622742976 deprecation_wrapper.py:119] From /Users/sakshishetty/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0723 23:08:55.644784 4622742976 deprecation_wrapper.py:119] From /Users/sakshishetty/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "n = xtrain.shape[1]  #number of columns in training data\n",
    "\n",
    "model.add(Dense(250, activation='sigmoid', input_shape=(n,)))\n",
    "model.add(Dense(250, activation='sigmoid'))\n",
    "model.add(Dense(250, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "#accuracy seems to vary vastly based on the usage of sigmoid or relu or softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0723 23:08:59.556368 4622742976 deprecation_wrapper.py:119] From /Users/sakshishetty/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0723 23:08:59.578849 4622742976 deprecation_wrapper.py:119] From /Users/sakshishetty/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0723 23:09:01.398101 4622742976 deprecation.py:323] From /Users/sakshishetty/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0723 23:09:01.424935 4622742976 deprecation_wrapper.py:119] From /Users/sakshishetty/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 113754 samples, validate on 28439 samples\n",
      "Epoch 1/10\n",
      "113754/113754 [==============================] - 5s 41us/step - loss: 0.1360 - acc: 0.9494 - val_loss: 0.0153 - val_acc: 0.9966\n",
      "Epoch 2/10\n",
      "113754/113754 [==============================] - 4s 37us/step - loss: 0.0426 - acc: 0.9849 - val_loss: 0.0102 - val_acc: 0.9984\n",
      "Epoch 3/10\n",
      "113754/113754 [==============================] - 4s 39us/step - loss: 0.0360 - acc: 0.9872 - val_loss: 0.0800 - val_acc: 0.9786\n",
      "Epoch 4/10\n",
      "113754/113754 [==============================] - 4s 39us/step - loss: 0.0352 - acc: 0.9873 - val_loss: 0.0093 - val_acc: 0.9961\n",
      "Epoch 5/10\n",
      "113754/113754 [==============================] - 5s 41us/step - loss: 0.0353 - acc: 0.9884 - val_loss: 0.0248 - val_acc: 0.9898\n",
      "Epoch 6/10\n",
      "113754/113754 [==============================] - 5s 40us/step - loss: 0.0337 - acc: 0.9892 - val_loss: 0.0440 - val_acc: 0.9826\n",
      "Epoch 7/10\n",
      "113754/113754 [==============================] - 5s 40us/step - loss: 0.0320 - acc: 0.9902 - val_loss: 0.0360 - val_acc: 0.9879\n",
      "Epoch 8/10\n",
      "113754/113754 [==============================] - 5s 41us/step - loss: 0.0299 - acc: 0.9907 - val_loss: 0.0039 - val_acc: 0.9999\n",
      "Epoch 9/10\n",
      "113754/113754 [==============================] - 5s 42us/step - loss: 0.0242 - acc: 0.9916 - val_loss: 0.0056 - val_acc: 0.9999\n",
      "Epoch 10/10\n",
      "113754/113754 [==============================] - 5s 45us/step - loss: 0.0278 - acc: 0.9911 - val_loss: 0.0046 - val_acc: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb34c20c18>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain, ytrain, validation_split=0.2, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
